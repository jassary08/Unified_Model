import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import os
from tqdm import tqdm
from model import Discriminator, Generator, create_models
from dataset import get_fashion_mnist_dataloader, show_imgs

def create_optimizers(D, G, lr_d=0.03, lr_g=0.03, optimizer_type='SGD'):
    if optimizer_type == 'SGD':
        optimizerD = torch.optim.SGD(D.parameters(), lr=lr_d)
        optimizerG = torch.optim.SGD(G.parameters(), lr=lr_g)
    elif optimizer_type == 'Adam':
        optimizerD = torch.optim.Adam(D.parameters(), lr=lr_d)
        optimizerG = torch.optim.Adam(G.parameters(), lr=lr_g)
    else:
        raise ValueError("optimizer_type must be 'SGD' or 'Adam'")
    return optimizerD, optimizerG

def train_step_discriminator(D, G, x_real, criterion, optimizerD, device, batch_size=64, z_dim=100):
    lab_real = torch.ones(batch_size, 1, device=device)
    lab_fake = torch.zeros(batch_size, 1, device=device)
    optimizerD.zero_grad()
    D_x = D(x_real)
    lossD_real = criterion(D_x, lab_real)

    z = torch.randn(batch_size, z_dim, device=device)
    x_gen = G(z).detach()
    D_G_z = D(x_gen)
    lossD_fake = criterion(D_G_z, lab_fake)

    lossD = lossD_real + lossD_fake
    lossD.backward()
    optimizerD.step()
    return lossD.item(), D_x.mean().item(), D_G_z.mean().item()

def train_step_generator(D, G, criterion, optimizerG, device, batch_size=64, z_dim=100):
    lab_real = torch.ones(batch_size, 1, device=device)
    optimizerG.zero_grad()
    z = torch.randn(batch_size, z_dim, device=device)
    x_gen = G(z)
    D_G_z = D(x_gen)
    lossG = criterion(D_G_z, lab_real)
    lossG.backward()
    optimizerG.step()
    return lossG.item(), D_G_z.mean().item()

def show_real_vs_fake(real_imgs, fake_imgs, num=8, save_path=None):
    """å¯¹æ¯”å±•ç¤ºçœŸå®å›¾åƒå’Œç”Ÿæˆå›¾åƒ"""
    assert real_imgs.size(0) >= num and fake_imgs.size(0) >= num, "å›¾åƒæ•°é‡ä¸è¶³"
    real_imgs = real_imgs[:num].cpu().detach()
    fake_imgs = fake_imgs[:num].cpu().detach()

    fig, axes = plt.subplots(2, num, figsize=(num * 1.5, 3))
    for i in range(num):
        axes[0, i].imshow(real_imgs[i][0], cmap='gray')
        axes[0, i].axis('off')
        if i == 0:
            axes[0, i].set_ylabel('Real', fontsize=12)

        axes[1, i].imshow(fake_imgs[i][0], cmap='gray')
        axes[1, i].axis('off')
        if i == 0:
            axes[1, i].set_ylabel('Fake', fontsize=12)

    plt.suptitle("real vs fake", fontsize=14)
    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, dpi=300)
    plt.show()

def save_checkpoint(D, G, optimizerD, optimizerG, epoch, loss_d, loss_g, save_dir='checkpoints'):
    """ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹"""
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    
    checkpoint = {
        'epoch': epoch,
        'discriminator_state_dict': D.state_dict(),
        'generator_state_dict': G.state_dict(),
        'optimizerD_state_dict': optimizerD.state_dict(),
        'optimizerG_state_dict': optimizerG.state_dict(),
        'loss_d': loss_d,
        'loss_g': loss_g,
    }
    
    checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch}.pth')
    torch.save(checkpoint, checkpoint_path)
    print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")

def save_models(D, G, save_dir='saved_models', model_type='vanilla'):
    """ä¿å­˜æœ€ç»ˆè®­ç»ƒå¥½çš„æ¨¡å‹"""
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    
    # ä¿å­˜ç”Ÿæˆå™¨
    generator_path = os.path.join(save_dir, f'generator_{model_type}.pth')
    torch.save(G.state_dict(), generator_path)
    print(f"ğŸ’¾ ç”Ÿæˆå™¨å·²ä¿å­˜: {generator_path}")
    
    # ä¿å­˜åˆ¤åˆ«å™¨
    discriminator_path = os.path.join(save_dir, f'discriminator_{model_type}.pth')
    torch.save(D.state_dict(), discriminator_path)
    print(f"ğŸ’¾ åˆ¤åˆ«å™¨å·²ä¿å­˜: {discriminator_path}")
    
    return generator_path, discriminator_path

def load_checkpoint(checkpoint_path, D, G, optimizerD, optimizerG, device):
    """åŠ è½½è®­ç»ƒæ£€æŸ¥ç‚¹"""
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    D.load_state_dict(checkpoint['discriminator_state_dict'])
    G.load_state_dict(checkpoint['generator_state_dict'])
    optimizerD.load_state_dict(checkpoint['optimizerD_state_dict'])
    optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])
    
    epoch = checkpoint['epoch']
    loss_d = checkpoint['loss_d']
    loss_g = checkpoint['loss_g']
    
    print(f"ğŸ“‚ æ£€æŸ¥ç‚¹å·²åŠ è½½: epoch {epoch}, D_loss: {loss_d:.4f}, G_loss: {loss_g:.4f}")
    return epoch, loss_d, loss_g

def load_models(generator_path, discriminator_path, device, latent_dim=100, img_shape=(1, 28, 28), model_type='vanilla'):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    D, G = create_models(device, latent_dim=latent_dim, img_shape=img_shape, model_type=model_type)
    
    G.load_state_dict(torch.load(generator_path, map_location=device))
    D.load_state_dict(torch.load(discriminator_path, map_location=device))
    
    print(f"ğŸ“‚ æ¨¡å‹å·²åŠ è½½: {generator_path}, {discriminator_path}")
    return D, G

def train_gan(epochs=3, batch_size=64, lr_d=0.03, lr_g=0.03, z_dim=100, device=None, model_type='vanilla', 
              save_interval=20, resume_from=None):
    """è®­ç»ƒGANæ¨¡å‹
    
    Args:
        epochs: è®­ç»ƒè½®æ¬¡
        batch_size: æ‰¹æ¬¡å¤§å°
        lr_d: åˆ¤åˆ«å™¨å­¦ä¹ ç‡
        lr_g: ç”Ÿæˆå™¨å­¦ä¹ ç‡
        z_dim: å™ªå£°ç»´åº¦
        device: è®¾å¤‡
        model_type: æ¨¡å‹ç±»å‹ ('vanilla' æˆ– 'dcgan')
        save_interval: ä¿å­˜æ£€æŸ¥ç‚¹çš„é—´éš”è½®æ¬¡
        resume_from: ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒçš„è·¯å¾„
    """
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f'Device: {device}')

    # ä¸ºFashionMNISTæ•°æ®é›†è®¾ç½®å›¾åƒå½¢çŠ¶
    img_shape = (1, 28, 28)
    D, G = create_models(device, latent_dim=z_dim, img_shape=img_shape, model_type=model_type)
    optimizerD, optimizerG = create_optimizers(D, G, lr_d, lr_g, 'Adam')  # æ”¹ç”¨Adamä¼˜åŒ–å™¨
    criterion = nn.BCELoss()
    dataloader, dataset = get_fashion_mnist_dataloader(batch_size=batch_size)

    start_epoch = 0
    
    # å¦‚æœæŒ‡å®šäº†æ¢å¤è·¯å¾„ï¼ŒåŠ è½½æ£€æŸ¥ç‚¹
    if resume_from and os.path.exists(resume_from):
        start_epoch, _, _ = load_checkpoint(resume_from, D, G, optimizerD, optimizerG, device)
        start_epoch += 1  # ä»ä¸‹ä¸€ä¸ªepochå¼€å§‹

    collect_x_gen = []
    fixed_noise = torch.randn(64, z_dim, device=device)
    fig = plt.figure()
    plt.ion()

    for epoch in range(start_epoch, epochs):
        print(f"\nğŸ§ª Epoch {epoch+1}/{epochs}")
        
        epoch_loss_d = 0
        epoch_loss_g = 0
        num_batches = len(dataloader)

        print("ğŸ” Training Discriminator:")
        d_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f"[D] Epoch {epoch+1}")
        for i, (x_real, _) in d_bar:
            x_real = x_real.to(device)
            current_batch_size = x_real.size(0)

            lossD, D_x_mean, D_G_z_mean = train_step_discriminator(
                D, G, x_real, criterion, optimizerD, device, current_batch_size, z_dim
            )
            
            epoch_loss_d += lossD

            d_bar.set_postfix({
                'LossD': f"{lossD:.4f}",
                'D(x)': f"{D_x_mean:.4f}",
                'D(G(z))': f"{D_G_z_mean:.4f}"
            })

        print("ğŸ¨ Training Generator:")
        g_bar = tqdm(range(len(dataloader)), desc=f"[G] Epoch {epoch+1}")
        for _ in g_bar:
            lossG, D_G_z_mean_gen = train_step_generator(
                D, G, criterion, optimizerG, device, batch_size, z_dim
            )
            
            epoch_loss_g += lossG

            g_bar.set_postfix({
                'LossG': f"{lossG:.4f}",
                'D(G(z))': f"{D_G_z_mean_gen:.4f}"
            })

        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss_d = epoch_loss_d / num_batches
        avg_loss_g = epoch_loss_g / num_batches
        
        print(f"ğŸ“Š Epoch {epoch+1} å¹³å‡æŸå¤± - D: {avg_loss_d:.4f}, G: {avg_loss_g:.4f}")

        x_gen = G(fixed_noise)
        show_imgs(x_gen, new_fig=False)
        fig.canvas.draw()
        collect_x_gen.append(x_gen.detach().clone())
        
        # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
        if (epoch + 1) % save_interval == 0:
            save_checkpoint(D, G, optimizerD, optimizerG, epoch, avg_loss_d, avg_loss_g)

    plt.ioff()
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    save_models(D, G, model_type=model_type)
    
    return D, G, collect_x_gen, dataset

def evaluate_gan(D, G, collect_x_gen, dataset):
    # è·å–ä¸€æ‰¹çœŸå®å›¾åƒ
    real_imgs, _ = next(iter(torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)))
    device = next(G.parameters()).device
    
    # ç”Ÿæˆ16ä¸ªä¸åŒçš„å™ªå£°å‘é‡
    z = torch.randn(16, 100, device=device)
    with torch.no_grad():
        fake_imgs = G(z)
    
    # å±•ç¤ºå¯¹æ¯”å›¾
    show_real_vs_fake(real_imgs, fake_imgs, num=8, save_path="real_vs_fake.png")
    
    # é¢å¤–å±•ç¤ºï¼šç”Ÿæˆæ›´å¤šä¸åŒçš„å›¾åƒæ¥éªŒè¯å¤šæ ·æ€§
    print("\nç”Ÿæˆå¤šæ ·æ€§æµ‹è¯•ï¼š")
    z_diverse = torch.randn(64, 100, device=device)
    with torch.no_grad():
        diverse_imgs = G(z_diverse)
    show_imgs(diverse_imgs[:16])  # æ˜¾ç¤ºå‰16å¼ 

if __name__ == "__main__":
    # è®­ç»ƒæ–°æ¨¡å‹
    D, G, collect_x_gen, dataset = train_gan(
        epochs=200,
        lr_d=0.0002,
        lr_g=0.0002,
        model_type='dcgan',  # åœ¨è¿™é‡ŒæŒ‡å®šæ¨¡å‹ç±»å‹
        save_interval=100,      # æ¯20ä¸ªepochä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹
        # resume_from='checkpoints/checkpoint_epoch_19.pth'  # å¯é€‰ï¼šä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    )
    evaluate_gan(D, G, collect_x_gen, dataset)
    
    # ç¤ºä¾‹ï¼šå¦‚ä½•åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹è¿›è¡Œæ¨ç†
    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    # D_loaded, G_loaded = load_models(
    #     'saved_models/generator_vanilla.pth',
    #     'saved_models/discriminator_vanilla.pth',
    #     device,
    #     model_type='vanilla'
    # )