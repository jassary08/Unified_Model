# WISE: A World Knowledge-Informed Semantic Evaluation for Text-to-Image Generation

## 研究背景与动机

![image-20250603183130412](C:\Users\田晋宇\AppData\Roaming\Typora\typora-user-images\image-20250603183130412.png)

近些年来，T2I模型被应用到艺术创作，新分子发现等各个领域，生成高质量艺术创作和视觉内容的能力越来越强大。图像生成模型包括基于Diffusion的专用文生图模型例如LDM，融合自回归模型和生成模型的统一架构例如gpt4o以及最近开源的Blip3o，后者能够更好的融合世界知识，例如画一个长鼻子的动物，统一模型能结合自回归模型中的世界知识，推断出要画一只大象，这种基于世界知识的视觉推理能力对于文生图模型来说至关重要。然而先前的研究和评估标准主要聚焦于图像生成的真实感和浅层的文本语义关系，缺乏对文本到图像生成中的复杂语义理解和世界知识集成的全面评估。

## 主要贡献

为了应对以上挑战，这篇工作的贡献点包括以下三个：

1. 提出了一个专门为生成模型的世界知识语义评估设计的基准。超越简单文本到图像像素的映射，评估标准包含了文化常识等25个子领域的1000个精心的设计的Prompt提示模型；
2. 引入了WiScore，用于评估知识图像对齐的新指标，超越了简单像素级和简单文本图像对齐；
3. 最终在10个专用文生图模型和12个统一架构模型上进行了基准测试，揭示了现有的一些文生图模型在世界知识整合能力上的局限性，推进理解生成统一架构的未来发展。

## 方法与技术细节

![image-20250603211624049](C:\Users\田晋宇\AppData\Roaming\Typora\typora-user-images\image-20250603211624049.png)

论文中介绍的基准测试流程可以分为四个步骤：

首先是数据准备部分。考虑倒现有的基准测试数据集中的Prompt设计大多采用了直接了当的形式，这些数据集主要为了评估文本到图像的简单像素还原能力，而无法评估模型的世界知识的整合能力以及把握更深层次的语义关系。因此这篇工作中从不同来源包括百科全书，教材，LLM生成语料中收集了1000条Prompt，包括文化常识，时空推理，自然科学三个大领域以及细化分出的25个子领域。文化常识要求模型掌握将视觉特征与特定文化尝试相结合的能力；时间推理评估时间和物体相对时间关系（eg. 迪拜时间晚上10点的自由女神像）；空间推理涵盖不同视图，地理关系，相对位置的评估；自然科学目标是评估模型是否能理解特定领域的专业知识，包括生物，化学，物理等等，生成与科学一致的图像。

<img src="https://github.com/PKU-YuanGroup/WISE/blob/main/assets/class.png?raw=true" alt="class.png" style="zoom:50%;" />

接着我们使用待评估的模型根据准备好的Prompt生成图像，进入到下一步的评估流程。

在评估的部分，选取gpt-4o作为评价器，通过特定的Prompt模板让gpt从一致性（consistency），真实性（Realism），美学质量（Aesthetic Quality）对待评估模型生成的图片进行评估，每个方面的评分分为三个等级0（Rejected），1（Conditional），2（Exemplary），最终为每个部分的评分定义一个权重，进行加权求和。在论文中作者给一致性，真实性，美学质量的权重分别为0.7，0.2，0.1，这样不仅能保证一致性在评分过程中起主导作用，还能融入部分真实性和美感质量，保持整体画面的质感。现有的一些评估指标例如CLIP-Score，VQA-Score在面对知识密集型的提示时，缺乏对隐式视觉理解和世界知识的敏感性，而论文提出的WiScore能够很好的评估生成图像所隐含的深层次视觉信息，论文中使用同一评分过程与不同评价指标进行可靠性测试，发现WiScore与人类评分最为一致。

<img src="C:\Users\田晋宇\AppData\Roaming\Typora\typora-user-images\image-20250603222547524.png" alt="image-20250603222547524" style="zoom:50%;" />

## 实验设计与结果

<img src="C:\Users\田晋宇\AppData\Roaming\Typora\typora-user-images\image-20250604003506591.png" alt="image-20250604003506591" style="zoom:50%;" />

论文选取了10个专用的T2I模型以及12个同意多模态模型进行Wise基准测试，模型均使用官方默认配置。最终实验发现代表统一多模态模型的GPT-4o获得了碾压性的最佳性能，在所有类别得分和总体得分上均优于其他模型，说明GPT-4o在利用世界知识生成复杂语义图像上的卓越能力；令人诧异的是主打生成理解统一能够融入更多世界知识的统一多模态模型在Wise基准测试中并没有取得优势，统一多模态大模型大多落后于专用生成模型，这也揭示了统一多模态模型发展过程中的面临的巨大挑战，需要重新思考现有的解决方案存在的弊端。

接着论文对两种不同类型模型在不同认知维度上的差异，主要使用了统计方法来进行验证。最终发现T2I 模型在前3个维度（文化、时间、空间）的平均分显著高于后3个科学维度（生物、物理、化学），表现出视觉表征的优势；同时，随着模型代际更新（如 SD 系列、Janus 系列），这种维度间的不平衡逐渐减小，说明新一代模型正逐步改善各维度的综合能力。

论文又对Prompt重写再次进行了实验，例如将 "常见母亲节植物" 改为 "康乃馨"，让语言更加简单直白。几乎所有模型的表现都明显提升，但是整体仍未达到令人满意的只是生成水平。简化提示语显著提升了模型表现暴露出当前模型在处理复杂世界知识方面的理解与生成双重瓶颈，未来需聚焦于模型本体能力的提升而非仅依赖提示设计技巧。

## 个人思考

1. 使用LLM作为评价器是否会存在随机性？多次评价生成的WiScore指标是否会不同？
2. Wise是为了评价生成任务中结合世界知识的能力，可以验证在统一多模态大模型架构中理解任务有利于提升生成任务的表现；但是生成任务对理解任务的表现提升仍然没有被很好探索，同时也需要一个benchmark来衡量生成对理解的增益。
3. 使用gpt-4o作为评价器评价gpt-4o生成的图片是否会有运动员下场当裁判的意思？分数是否会虚高？